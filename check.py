#!/usr/bin/env python
"""
í˜•íƒœì†Œ ë¶„ì„ â†’ BM25/Vector ê²€ìƒ‰ â†’ Parent-Child â†’ LLM ì „ë‹¬ ê³¼ì • í™•ì¸
"""

import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent / "backend"))

from backend.rag.tokenizer import KiwiTokenizer
from backend.rag.vectorstore import QdrantVectorStore
from backend.rag.embedder import BGEEmbedder
from backend.rag.retriever import RAGRetriever


def test_full_flow():
    print("=" * 80)
    print("ğŸ” RAG Parent-Child ì „ì²´ íë¦„ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "ì¡°ê¸°ì¬ì·¨ì—…ìˆ˜ë‹¹ ë°›ìœ¼ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´ìš”",  # í•©ì„±ì–´ í¬í•¨
        "ê¶Œê³ ì‚¬ì§ ì¦ê±°ê°€ ì—†ìœ¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”",     # FAQ ë³€í˜•
        "2025ë…„ ì‹¤ì—…ê¸‰ì—¬ í•˜í•œì•¡ì´ ì–¼ë§ˆì¸ê°€ìš”"       # ìƒˆë¡œìš´ ì§ˆë¬¸
    ]

    for query_idx, test_query in enumerate(test_queries, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ {query_idx}: '{test_query}'")
        print("-" * 80)

        # 1. í˜•íƒœì†Œ ë¶„ì„
        print("\n[1ë‹¨ê³„] Kiwi í˜•íƒœì†Œ ë¶„ì„")
        print("-" * 40)
        tokenizer = KiwiTokenizer()
        tokens = tokenizer.tokenize(test_query)
        print(f"ì›ë¬¸: {test_query}")
        print(f"í† í°: {tokens}")
        print(f"í† í° ìˆ˜: {len(tokens)}ê°œ")

        # 2. ë™ì˜ì–´ í™•ì¥
        expanded = tokenizer.expand_query(tokens)
        print(f"ë™ì˜ì–´ í™•ì¥: {expanded}")

        # 3. BM25 ê²€ìƒ‰
        print("\n[2ë‹¨ê³„] BM25 í‚¤ì›Œë“œ ê²€ìƒ‰")
        print("-" * 40)
        vector_store = QdrantVectorStore()
        vector_store._load_all_documents()  # BM25 ì´ˆê¸°í™”

        bm25_results = vector_store.bm25_search(test_query, top_k=3)
        print(f"BM25 ê²€ìƒ‰ ê²°ê³¼: {len(bm25_results)}ê°œ")
        for i, doc in enumerate(bm25_results, 1):
            print(f"\n  [{i}] BM25 Score: {doc['score']:.3f}")
            print(f"      Text: {doc['text'][:60]}...")

        # 4. Vector ê²€ìƒ‰
        print("\n[3ë‹¨ê³„] Vector ì˜ë¯¸ ê²€ìƒ‰")
        print("-" * 40)
        embedder = BGEEmbedder()
        query_embedding = embedder.embed_query(test_query)

        vector_results = vector_store.search(query_embedding, top_k=3)
        print(f"Vector ê²€ìƒ‰ ê²°ê³¼: {len(vector_results)}ê°œ")
        for i, doc in enumerate(vector_results, 1):
            print(f"\n  [{i}] Vector Score: {doc['score']:.3f}")
            print(f"      Text: {doc['text'][:60]}...")

        # 5. Hybrid ê²€ìƒ‰ (ìµœì¢…)
        print("\n[4ë‹¨ê³„] Hybrid ê²€ìƒ‰ (BM25 + Vector ê²°í•©)")
        print("-" * 40)
        hybrid_results = vector_store.hybrid_search(test_query, query_embedding, top_k=3)
        print(f"Hybrid ê²€ìƒ‰ ê²°ê³¼: {len(hybrid_results)}ê°œ")

        for i, doc in enumerate(hybrid_results, 1):
            print(f"\n  [{i}] Hybrid Score: {doc['hybrid_score']:.3f}")
            print(f"      BM25 RRF: {doc.get('bm25_rrf', 0):.3f}")
            print(f"      Vector RRF: {doc.get('vector_rrf', 0):.3f}")
            print(f"      Text (Child): {doc['text'][:60]}...")
            if "parent_text" in doc:
                print(f"      Parent Text: {doc['parent_text'][:100]}...")

        # 6. ìµœì¢… ì ìˆ˜ íŒì •
        print("\n[5ë‹¨ê³„] RAG ì ìˆ˜ íŒì •")
        print("-" * 40)
        relevance_score = hybrid_results[0]["hybrid_score"] if hybrid_results else 0.0
        print(f"ìµœê³  ì ìˆ˜: {relevance_score:.3f}")
        
        if relevance_score < 0.15:
            print("âŒ RAG ì ìˆ˜ ë‚®ìŒ â†’ LLM ë‹¨ë… ëª¨ë“œë¡œ ì „í™˜")
        elif relevance_score < 0.3:
            print("âš ï¸ RAG Lite ëª¨ë“œ (ì ìˆ˜ ë³´í†µ)")
        else:
            print("âœ… RAG Full ëª¨ë“œ (ì ìˆ˜ ë†’ìŒ)")

        print("\n" + "="*80)


if __name__ == "__main__":
    test_full_flow()